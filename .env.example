POSTGRES_DB=ragdb
POSTGRES_USER=raguser
POSTGRES_PASSWORD=ragpass
NEXT_PUBLIC_API_BASE=http://localhost:18000
CHAT_PROVIDER_BASE_URL=https://api.openai.com/v1

# Auth and keys
API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AUTH_USERS="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
AUTH_TOKEN_SECRET=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AUTH_TOKEN_TTL_SECONDS=86400
OPENAI_ORG=org-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_PROJECT=proj_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Embeddings
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_PROVIDER_BASE_URL=https://api.openai.com/v1
EMBEDDING_MODEL=EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_TARGET_DIM=3072
EMBEDDING_BATCH_SIZE=64
EMBEDDING_MAX_RETRIES=6
EMBEDDING_BACKOFF_BASE=1.0

# Chat/completions
CHAT_MODEL=gpt-5-chat-latest
CHAT_TEMPERATURE=0.2
CHAT_TOP_P=1.0
CHAT_MAX_TOKENS=1024
CHAT_MAX_RETRIES=5
CHAT_BACKOFF_BASE=0.6

# RAG tuning
MAX_CANDIDATE_CHUNKS=96
MAX_CHUNK_CHARS=1200
CHUNK_OVERLAP=250
TOP_K=24

# OCR and timeouts
TESS_LANGS="spa+eng"
HTTP_TIMEOUT_SECONDS=60

# CORS
ALLOWED_ORIGINS=*

# Provider selection defaults
LLM_PROVIDER=openai
EMBEDDING_PROVIDER=openai
ENABLE_PROVIDER_FALLBACK=true
# Preferred chat provider when the frontend does not specify one
# Accepts: openai | deepseek | gemini
DEFAULT_CHAT_PROVIDER=openai

# OpenAI
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
EMBEDDING_MODEL=text-embedding-3-large

# DeepSeek
DEEPSEEK_API_BASE=https://api.deepseek.com/v1
DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
DEEPSEEK_CHAT_MODEL=deepseek-chat
DEEPSEEK_EMBEDDING_MODEL=deepseek-embedder

# Gemini (Google Generative Language API)
# If using Gemini from Google AI Studio/Generative Language API
GEMINI_API_BASE=https://generativelanguage.googleapis.com/v1beta
GEMINI_API_KEY=AIza-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
GEMINI_CHAT_MODEL=gemini-flash-latest
# Enable server-side context caching for large system prompts
GEMINI_ENABLE_CONTEXT_CACHE=true
# Cache TTL for server-side cached content (seconds)
GEMINI_CACHE_TTL_SECONDS=1800
# Minimum size (characters) of system/context text to attempt caching
GEMINI_CACHE_MIN_CHARS=4000
GEMINI_MAX_TOKENS=8192
GCP_LOCATION=us-east1
GEMINI_PROJECT_NAME=projects/213082693271
GEMINI_PROJECT_NUMBER=213082693271

# Frontend default LLM
NEXT_PUBLIC_DEFAULT_LLM=deepseek
#NEXT_PUBLIC_DEFAULT_LLM=gpt     # gpt | deepseek | gemini
#NEXT_PUBLIC_DEFAULT_LLM=gemini
